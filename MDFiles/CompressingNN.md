## Compressing Neural Networks
- [Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding](https://arxiv.org/abs/1510.00149): 35-49x compression without loss of accuracy.

- [Compressing Neural Networks with the Hashing Trick](https://arxiv.org/abs/1504.04788):  Use Hashing to compress networks.

- [MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications](https://arxiv.org/abs/1704.04861): For phones and embedded devices.

- [Learning to Prune Filters in Convolutional Neural Networks](https://arxiv.org/abs/1801.07365): Prune to compress network by selecting maximum tolerable loss in accuracy. Good for choosing the trade-off between model size and accuacy.

- [Online Embedding Compression for Text Classification using Low Rank Matrix Factorization](https://arxiv.org/pdf/1811.00641): Presents a method for compression using online low rank factorization, from Amazon Alexa team. Not sure if it'll work with deconv layers and on images. 
```diff
- TODO Paper Summary
```
